---
title: "R Notebook"
output: html_notebook
---

Goal: Predict Diabetes Incidence in Pima Indians

Data Loading
```{r}
library("mlbench")
data("PimaIndiansDiabetes")

# Rename Data
data = PimaIndiansDiabetes
data

# Set Seed
set.seed(415)

# Split training and test
index = sample(1:nrow(data), round(0.8*nrow(data)))
train = data[index,]
test = data[-index,]
```

Data Inspection
```{r}
# Data Preview
head(data)

# Turning Diabetes column into binary 
data$diabetes = ifelse(data$diabetes == "pos", 1, 0)
data$diabetes = as.factor(data$diabetes)

# Check for NAs in columns
apply(data, 2, function(x) sum(is.na(x)))

# Descriptive Measures
sum(data$diabetes == 0) # 500 obs
sum(data$diabetes == 1) # 268 obs
```

Modeling

Basic Linear Regression
```{r}
# Build basic linear regression
linear = lm(diabetes ~., train)

# Make Predictions from basic linear model
pred_linear = ifelse(predict(linear, test, type = "response") >= 0.5, 1, 0)

# Confusion matrix
table(test$diabetes, pred_linear, dnn = c("No Diabetes", "Diabetes"))

# Accuracy Rate: 76.62%
(87+31)/(length(pred_linear))
```
Started off with an accuracy rate of around 77 percent. 

Cross-valided Linear Regression
```{r}
library(caret)
# Set control parameters for train
lm_ctrl = trainControl(method = "cv", number = 10)

# Build cross-validated linear model
cv.linear = train(diabetes~., data = train, method = "lm", trControl = lm_ctrl)

# Making predictions
pred_cv.linear = ifelse(predict(cv.linear, test) >= 0.5, 1, 0)

# Confusion matrix
table(test$diabetes, pred_cv.linear, dnn = c("No Diabetes", "Diabetes"))

# Accuracy Rate is the same as basic linear regression
```
Same accuracy rate as regular linear regression. On to more advanced techniques.

Random Forest
```{r}
library(randomForest)

# Splitting data into x and y matrices
train_y = train[,9]
train_x = train[,-9]

# Building a random forest
rForest = randomForest(diabetes ~ ., data = train)

# Making predictions
pred_rf = ifelse(predict(rForest, test) >= 0.5, 1, 0)

# Confusion Matrix
table(test$diabetes, pred_rf, dnn = c("No Diabetes", "Diabetes"))

# Accuracy Rate
(87+35)/(length(pred_rf))
```
Up to a 79% accuracy rate with random forests.

Neural Net
```{r}
library(neuralnet)

# Scaling Data
maxs = apply(data, 2, max)
mins = apply(data, 2, min)

scaled = as.data.frame(scale(data, center = mins, scale = maxs - mins))

train_scaled = scaled[index,]
test_scaled = scaled[-index,]

# Building a neural net
# This example has two hidden layers; 5 and 3 nodes.
n = names(train_scaled)
f = as.formula(paste("diabetes ~", paste(n[!n %in% "diabetes"], collapse = " + ")))

nn = neuralnet(f, data = train_scaled, hidden = 8, linear.output = F)

# Making neural net predictions
nn_prob = ifelse(compute(nn, test_scaled[,1:8])$net.result >= 0.5, 1, 0)

confusionMatrix(data = test$diabetes, nn_prob)

# Accuracy Rate with hidden layer of 6
(83+42)/(length(pred_nn_prob)) # 81.17%

# Accuracy Rate with hidden layer of 8
(85+47)/(length(pred_nn_prob)) # 85.71%

nn2 = train(f, data = train_scaled, method='neuralnet', tuneGrid = expand.grid(.layer1=c(6), .layer2 = c(0), .layer3 = c(0)), linear.output = F)
```
Accuracy rate has fallen with a neural net

Neural Net v2
```{r}
#Fit model
library(caret)
nn2 = train(diabetes~., train, method='nnet', linout=FALSE, trace = FALSE,
                #Grid of tuning parameters to try:
                tuneGrid=expand.grid(.size=6,.decay=c(0,0.001,0.1))) 

temp = predict(nn2, test_scaled)
pred_nn_prob = temp*(max(data$diabetes) - min(data$diabetes)) + min(data$diabetes) 
table(test$diabetes, temp, dnn = c("No Diabetes", "Diabetes"))
```